{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multinomial Naive Bayes Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyuVWdjjSBTy"
      },
      "source": [
        "# **Name - PRABHAKAR KUMAR**\r\n",
        "# **Roll - IRM2017008**\r\n",
        "# **Naive Bayes Assignment Part 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDt-NE1RLSf2"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from collections import defaultdict\r\n",
        "import string"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJIT2QOzSfvq"
      },
      "source": [
        "#**Loading Dataset and preparing Testing and Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls5Rh2L7MEpn",
        "outputId": "b6216fc9-1d8c-438b-b1f8-006f7702faa9"
      },
      "source": [
        "df = pd.read_csv(\"spam ham data set.csv\",encoding='latin-1')\r\n",
        "df.dropna(axis=1, inplace=True)\r\n",
        "df.head"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of         v1                                                 v2\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham              Will ÃŒ_ b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsG7MZfxMHpN",
        "outputId": "96abbe38-5719-4fe6-9dcc-9dc88f9ca0b2"
      },
      "source": [
        "row_count = len(df.index)\r\n",
        "train_count = int(0.7*row_count)\r\n",
        "print(train_count)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UniMWyfpMgBj"
      },
      "source": [
        "trainSet = df[:3900]\r\n",
        "testSet = df[3900:]\r\n",
        "testSet.reset_index(inplace=True,drop=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OFbJUnNSsWP"
      },
      "source": [
        "# **Calculating CLass Prior Probability and Likelihood**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnmKxkLTMxx9",
        "outputId": "03093acf-01e7-45c9-bd35-369f68394069"
      },
      "source": [
        "spamCount = 0\r\n",
        "hamCount = 0\r\n",
        "totalCount =  0\r\n",
        "spamDict = defaultdict(int)\r\n",
        "hamDict = defaultdict(int)\r\n",
        "for index,row in trainSet.iterrows():\r\n",
        "    totalCount+=1\r\n",
        "\r\n",
        "    # Splitting each text content into list of words\r\n",
        "    wordList = str(row['v2']).split()\r\n",
        "\r\n",
        "    # Removing Punctuations marks and lower casing from the words as they have no significance towards the model\r\n",
        "    wordList = [(word.translate(str.maketrans('', '', string.punctuation))).lower() for word in wordList]\r\n",
        "\r\n",
        "    # Removing empty words, as some empty words after removal of punctuations may have occured\r\n",
        "    wordList = [word for word in wordList if word != '']\r\n",
        "\r\n",
        "    if str(row['v1'])=='spam':\r\n",
        "        spamCount+=1\r\n",
        "        tempDict = spamDict\r\n",
        "    else:\r\n",
        "        hamCount+=1\r\n",
        "        tempDict = hamDict\r\n",
        "    for word in wordList:\r\n",
        "        tempDict[word] = tempDict[word]+1\r\n",
        "\r\n",
        "print(totalCount)\r\n",
        "print(spamCount)\r\n",
        "print(hamCount)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3900\n",
            "519\n",
            "3381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nQ3VSdaNCeh",
        "outputId": "887e45fc-37b1-4ff1-cea0-8e9d604a0a35"
      },
      "source": [
        "pSpam = spamCount/totalCount\r\n",
        "print(pSpam)\r\n",
        "pHam = hamCount/totalCount\r\n",
        "print(pHam)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.13307692307692306\n",
            "0.8669230769230769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDfSMN6MO5wM"
      },
      "source": [
        "# **Applying Laplace Smoothing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux2nqAnsOzYV"
      },
      "source": [
        "alpha = 1\r\n",
        "k = 2\r\n",
        "pWordSpamDict = {}\r\n",
        "pWordHamDict = {}\r\n",
        "for key in spamDict:\r\n",
        "    pWordSpamDict[key] = (spamDict[key] + alpha)/(spamCount + (alpha*k))\r\n",
        "for key in hamDict:\r\n",
        "    pWordHamDict[key] = (hamDict[key] + alpha)/(hamCount + (alpha*k))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV1GL_fMPM5V"
      },
      "source": [
        "# **Probability of Mail being Spam using Laplace Smoothing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7kJ30W-O99W"
      },
      "source": [
        "def spamProb(wordList):\r\n",
        "    wordSpamProb = []\r\n",
        "    for word in wordList:\r\n",
        "        if word in pWordSpamDict:\r\n",
        "            wordSpamProb.append(pWordSpamDict[word])\r\n",
        "        else:\r\n",
        "            p = (alpha)/(spamCount + alpha*k)\r\n",
        "            wordSpamProb.append(p)\r\n",
        "    prob = pSpam\r\n",
        "    for item in wordSpamProb:\r\n",
        "        prob*=item\r\n",
        "    return prob"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goLN-P_jPYs4"
      },
      "source": [
        "# **Probability of Mail being Ham using Laplace Smoothing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0wWL08BPUDz"
      },
      "source": [
        "def hamProb(wordList):\r\n",
        "    wordHamProb = []\r\n",
        "    for word in wordList:\r\n",
        "        if word in pWordHamDict:\r\n",
        "            wordHamProb.append(pWordHamDict[word])\r\n",
        "        else:\r\n",
        "            p = (alpha)/(hamCount + alpha*k)\r\n",
        "            wordHamProb.append(p)\r\n",
        "    prob = pHam\r\n",
        "    for item in wordHamProb:\r\n",
        "        prob*=item\r\n",
        "    return prob"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPxA1-oJPxKA"
      },
      "source": [
        "# **Testing of Model over Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGevc-NaPcsw",
        "outputId": "e886a21f-80f2-4e48-a9d9-c7fe9f5b0140"
      },
      "source": [
        "actual = np.zeros(len(testSet.index), dtype=int)\r\n",
        "predicted = np.zeros(len(testSet.index), dtype=int)\r\n",
        "for index, row in testSet.iterrows():\r\n",
        "    if str(row['v1'])=='spam':\r\n",
        "        actual[index] = 1\r\n",
        "    else:\r\n",
        "        actual[index] = 0\r\n",
        "    \r\n",
        "    mail = str(row['v2'])\r\n",
        "    wordList = str(mail).split()\r\n",
        "    wordList = [(word.translate(str.maketrans('', '', string.punctuation))).lower() for word in wordList]\r\n",
        "    wordList = [word for word in wordList if word != '']\r\n",
        "    \r\n",
        "    pSpamMail = spamProb(wordList)\r\n",
        "    pHamMail = hamProb(wordList)\r\n",
        "    \r\n",
        "    if pSpamMail > pHamMail:\r\n",
        "        predicted[index] = 1\r\n",
        "    else:\r\n",
        "        predicted[index] = 0\r\n",
        "        \r\n",
        "print('TOTAL SAMPLES : ' + str(len(testSet.index)))\r\n",
        "print('SAMPLES CLASSIFIED CORRECTLY : ' + str(np.sum(actual == predicted)))\r\n",
        "print('SAMPLES CLASSIFIED INCORRECTLY : ' + str(len(testSet.index) - np.sum(actual == predicted)))\r\n",
        "print('MODEL ACCURACY : ' + str(((np.sum(actual == predicted))/(len(testSet.index)))*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOTAL SAMPLES : 1672\n",
            "SAMPLES CLASSIFIED CORRECTLY : 1271\n",
            "SAMPLES CLASSIFIED INCORRECTLY : 401\n",
            "MODEL ACCURACY : 76.01674641148325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgGb_7LTTAlR"
      },
      "source": [
        "# **Accuracy Parameters of the Model over Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubmzuTsJQN_X",
        "outputId": "027a9e4a-a3e4-4a17-bd1c-a28d23fd492d"
      },
      "source": [
        "tp=0\r\n",
        "tn=0\r\n",
        "fp=0\r\n",
        "fn=0\r\n",
        "for i in range(1672):\r\n",
        "    if actual[i]==predicted[i]and actual[i]==0:\r\n",
        "        tp+=1\r\n",
        "    if actual[i]!=predicted[i]and actual[i]==0:\r\n",
        "        fp+=1\r\n",
        "    if actual[i]==predicted[i]and actual[i]==1:\r\n",
        "        tn+=1\r\n",
        "    if actual[i]!=predicted[i]and actual[i]==1:\r\n",
        "        fn+=1\r\n",
        "\r\n",
        "print(\"CONFUSION MATRIX\")\r\n",
        "print(tp,\" \",fp)\r\n",
        "print(fn,\" \",tn)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX\n",
            "1043   401\n",
            "0   228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04enHOCGQtnS",
        "outputId": "40771b11-1b80-4f62-9bd4-ccb7baff44cd"
      },
      "source": [
        "print(\"Accuracy : \",str((tp+tn)/(tp+fp+tn+fn)))\r\n",
        "print(\"Precision : \",str((tp)/(tp+fp)))\r\n",
        "print(\"Sensitivity : \",str((tp)/(tp+fn)))\r\n",
        "print(\"Specificity : \",str((tn)/(fp+tn)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.7601674641148325\n",
            "Precision :  0.7222991689750693\n",
            "Sensitivity :  1.0\n",
            "Specificity :  0.3624801271860095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn6D9fMkTX05"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}